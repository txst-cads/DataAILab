name: CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

env:
  NODE_VERSION: '18'
  PYTHON_VERSION: '3.9'

jobs:
  test:
    name: Run Tests
    runs-on: ubuntu-latest
    environment: cads-research
    
    services:
      postgres:
        image: postgres:14
        env:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: test_db
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
          cache-dependency-path: 'requirements.txt'

      - name: Set up Node.js
        uses: actions/setup-node@v5
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Debug environment
        run: |
          echo "Python version: $(python --version)"
          echo "Current directory: $(pwd)"
          echo "Requirements file check:"
          ls -la requirements.txt
          echo "CADS directory check:"
          ls -la cads/ || echo "CADS directory structure may differ in CI"
          echo "Project structure:"
          ls -la

      - name: Set up test environment variables
        run: |
          echo "DATABASE_URL=postgresql://postgres:postgres@localhost:5432/test_db" >> $GITHUB_ENV
          echo "SUPABASE_URL=${{ secrets.DATABASE_URL }}" >> $GITHUB_ENV
          echo "OPENALEX_EMAIL=test@example.com" >> $GITHUB_ENV
          echo "GROQ_API_KEY=${{ secrets.GROQ_API_KEY }}" >> $GITHUB_ENV
          echo "CI=true" >> $GITHUB_ENV

      - name: Generate comprehensive test data
        run: |
          echo "ğŸ”§ Generating comprehensive test data for CI environment..."
          python3 scripts/ci/generate_test_data.py
          
          echo "ğŸ“‹ Verifying generated files..."
          ls -la data/processed/
          ls -la visuals/public/data/
          
          echo "ğŸ“Š File sizes:"
          find data/ visuals/public/data/ -name "*.json" -exec ls -lh {} \;
          echo "ğŸ“¦ Compressed files:"
          find data/ visuals/public/data/ -name "*.gz" -exec ls -lh {} \;
          
          echo "âœ… Comprehensive test data generated successfully"

      - name: Run comprehensive test suite
        run: |
          chmod +x .github/scripts/run-tests.sh
          ./.github/scripts/run-tests.sh

  deploy:
    name: Deploy to Vercel
    needs: test
    runs-on: ubuntu-latest
    environment: cads-research
    # Only deploy if tests pass AND we're on main branch AND it's a push (not PR)
    if: success() && github.ref == 'refs/heads/main' && github.event_name == 'push'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Verify test job succeeded
        run: |
          echo "âœ… All tests passed successfully - proceeding with deployment"
          echo "Branch: ${{ github.ref }}"
          echo "Event: ${{ github.event_name }}"

      - name: Debug Vercel configuration
        run: |
          echo "ğŸ” Verifying Vercel environment variables..."
          echo "VERCEL_TOKEN: ${{ secrets.VERCEL_TOKEN != '' && 'SET' || 'NOT SET' }}"
          echo "VERCEL_ORG_ID: ${{ secrets.VERCEL_ORG_ID != '' && 'SET' || 'NOT SET' }}"
          echo "VERCEL_PROJECT_ID: ${{ secrets.VERCEL_PROJECT_ID != '' && 'SET' || 'NOT SET' }}"
          echo "Environment: cads-research"

      - name: Install Vercel CLI
        run: npm install -g vercel@latest


      - name: Deploy to Vercel
        run: |
          echo "ğŸš€ Starting Vercel deployment..."
          
          # Verify required environment variables
          if [ -z "$VERCEL_TOKEN" ]; then
            echo "âŒ VERCEL_TOKEN is not set"
            exit 1
          fi
          
          echo "âœ… Vercel token is set"
          echo "ğŸ”§ Deploying with project auto-discovery..."
          
          # Deploy and let Vercel handle project creation/linking
          echo "ğŸš€ Deploying CADS Visualizer..."
          echo "ğŸ“ Deploying from directory: visuals/public-prod/"
          
          # Change to the correct directory for deployment
          cd visuals/public-prod/
          
          # List directory contents to verify we're in the right place
          echo "ğŸ“‹ Directory contents:"
          ls -la
          
          # Run Vercel deployment with better error handling
          echo "ğŸš€ Executing Vercel deployment..."
          set +e  # Don't exit on error immediately
          DEPLOYMENT_OUTPUT=$(vercel --prod --token "$VERCEL_TOKEN" --yes 2>&1)
          VERCEL_EXIT_CODE=$?
          set -e  # Re-enable exit on error
          
          echo "ğŸ“‹ Full Vercel output:"
          echo "$DEPLOYMENT_OUTPUT"
          echo "ğŸ” Vercel exit code: $VERCEL_EXIT_CODE"
          
          if [ $VERCEL_EXIT_CODE -ne 0 ]; then
            echo "âŒ Vercel command failed with exit code $VERCEL_EXIT_CODE"
            echo "ğŸ’¥ This is the complete error output from Vercel:"
            echo "$DEPLOYMENT_OUTPUT"
            exit 1
          fi
          
          # Extract the production URL from the output (more precise)
          DEPLOYMENT_URL=$(echo "$DEPLOYMENT_OUTPUT" | grep -E "Production: https://.*\.vercel\.app" | sed 's/.*Production: \(https:\/\/[^ ]*\).*/\1/' | head -1)
          
          # Fallback: try alternative extraction if first method fails
          if [ -z "$DEPLOYMENT_URL" ]; then
            DEPLOYMENT_URL=$(echo "$DEPLOYMENT_OUTPUT" | grep -oE "https://[a-zA-Z0-9-]+\.vercel\.app" | head -1)
          fi
          
          if [ -z "$DEPLOYMENT_URL" ]; then
            echo "âŒ Failed to extract deployment URL from Vercel output"
            echo "ğŸ” Full Vercel output for debugging:"
            echo "$DEPLOYMENT_OUTPUT"
            exit 1
          fi
          
          echo "âœ… Deployment successful!"
          echo "ğŸ“ Deployment URL: $DEPLOYMENT_URL"
          
          # Save URL for health check
          echo "DEPLOYMENT_URL=$DEPLOYMENT_URL" >> $GITHUB_ENV
        env:
          VERCEL_TOKEN: ${{ secrets.VERCEL_TOKEN }}

      - name: Wait for Vercel deployment to be ready
        run: |
          echo "â³ Waiting for Vercel deployment to be fully ready..."
          echo "ğŸ”— Deployment URL: $DEPLOYMENT_URL"
          
          # Extract deployment ID from URL for status checking
          DEPLOYMENT_ID=$(echo "$DEPLOYMENT_URL" | grep -oE '[a-z0-9-]+(?=\.)' | head -1 || echo "")
          
          # Simple polling approach - test the URL directly
          MAX_ATTEMPTS=20
          WAIT_TIME=30
          
          for attempt in $(seq 1 $MAX_ATTEMPTS); do
            echo "ğŸ” Checking deployment readiness (attempt $attempt/$MAX_ATTEMPTS)..."
            
            # Test basic connectivity with a reasonable timeout
            if curl -f -s --max-time 15 "$DEPLOYMENT_URL" > /dev/null 2>&1; then
              echo "âœ… Deployment is ready and responding!"
              break
            else
              if [ $attempt -eq $MAX_ATTEMPTS ]; then
                echo "âŒ Deployment failed to become ready after $MAX_ATTEMPTS attempts"
                echo "ğŸ” Final connectivity test with verbose output:"
                curl -v --max-time 20 "$DEPLOYMENT_URL" || true
                exit 1
              fi
              echo "â³ Deployment not ready yet, waiting ${WAIT_TIME}s..."
              sleep $WAIT_TIME
            fi
          done
        env:
          VERCEL_TOKEN: ${{ secrets.VERCEL_TOKEN }}

      - name: Pre-health check verification
        run: |
          echo "ğŸ” Verifying deployment is ready to serve traffic..."
          echo "ğŸ“ Testing URL: $DEPLOYMENT_URL"
          
          # Simple connectivity test with basic retry
          for attempt in {1..3}; do
            echo "ğŸ” Basic connectivity test (attempt $attempt/3)..."
            if curl -f -s --max-time 10 "$DEPLOYMENT_URL" > /dev/null; then
              echo "âœ… Basic connectivity confirmed"
              break
            else
              if [ $attempt -eq 3 ]; then
                echo "âŒ Basic connectivity failed after 3 attempts"
                echo "ğŸ” Testing with verbose output..."
                curl -v --max-time 15 "$DEPLOYMENT_URL" || true
                exit 1
              fi
              echo "â³ Waiting 15s before retry..."
              sleep 15
            fi
          done
          
          echo "âœ… Deployment verified - proceeding with comprehensive health checks"

      - name: Health check
        run: |
          echo "ğŸ¥ Running post-deployment health check..."
          echo "ğŸ“ Testing URL: $DEPLOYMENT_URL"
          
          # Enhanced function to test endpoints with exponential backoff
          test_endpoint() {
            local url="$1"
            local description="$2"
            local max_attempts=10
            local base_wait_time=30
            
            for attempt in $(seq 1 $max_attempts); do
              # Calculate wait time with exponential backoff (30s, 60s, 120s, 240s, max 240s)
              local wait_time=$((base_wait_time * (attempt > 4 ? 8 : 2**(attempt-1))))
              
              echo "ğŸ” Testing $description (attempt $attempt/$max_attempts)..."
              
              # Use longer timeout and get more detailed response info
              local response
              response=$(curl -f -s -w "HTTP_%{http_code}_Size_%{size_download}_Time_%{time_total}" --max-time 30 "$url" 2>&1)
              local curl_exit_code=$?
              
              if [ $curl_exit_code -eq 0 ]; then
                echo "âœ… $description - SUCCESS: $response"
                return 0
              else
                echo "âŒ $description - Failed (attempt $attempt/$max_attempts): $response"
                if [ $attempt -lt $max_attempts ]; then
                  echo "â³ Waiting ${wait_time}s before retry (exponential backoff)..."
                  sleep $wait_time
                fi
              fi
            done
            
            echo "ğŸ’¥ $description - All attempts failed after $max_attempts retries"
            return 1
          }
          
          # No additional wait - deployment status verification already handled this
          echo "ğŸš€ Starting comprehensive health checks (deployment already verified ready)..."
          
          # Test main page with detailed error reporting
          if ! test_endpoint "$DEPLOYMENT_URL" "Main page"; then
            echo "ğŸš¨ Critical: Main page failed - investigating..."
            curl -v --max-time 30 "$DEPLOYMENT_URL" || true
            exit 1
          fi
          
          # Test data endpoint
          if ! test_endpoint "$DEPLOYMENT_URL/data/visualization-data.json" "Data endpoint"; then
            echo "âš ï¸ Warning: Data endpoint failed but continuing..."
          fi
          
          # Test static assets
          if ! test_endpoint "$DEPLOYMENT_URL/app.js" "JavaScript assets"; then
            echo "âš ï¸ Warning: JavaScript assets failed but main page works"
          fi
          
          echo "ğŸ‰ Health checks completed!"
          echo "ğŸš€ Deployment is operational at: $DEPLOYMENT_URL"
          echo "ğŸ“Š Note: Some non-critical endpoints may still be propagating"


      - name: Deployment success notification
        run: |
          echo "ğŸš€ Deployment completed successfully!"
          echo "ğŸ“ Live URL: $DEPLOYMENT_URL"
          echo "ğŸ¯ All health checks passed - application is fully operational"
          echo "ğŸ“Š Sentry monitoring ready (configured in frontend)"

  # This job runs when tests fail to provide clear feedback
  test-failure-notification:
    name: Test Failure Notification
    needs: test
    runs-on: ubuntu-latest
    if: failure() && github.ref == 'refs/heads/main' && github.event_name == 'push'
    
    steps:
      - name: Test failure notification
        run: |
          echo "âŒ Tests failed - deployment blocked!"
          echo "Branch: ${{ github.ref }}"
          echo "Event: ${{ github.event_name }}"
          echo "Please fix the failing tests before deployment can proceed."
          exit 1

  # Summary job that always runs to provide final status
  summary:
    name: Pipeline Summary
    needs: [test, deploy]
    runs-on: ubuntu-latest
    if: always()
    
    steps:
      - name: Pipeline summary
        run: |
          echo "ğŸ“‹ CI/CD Pipeline Summary"
          echo "======================="
          echo "Test Status: ${{ needs.test.result }}"
          echo "Deploy Status: ${{ needs.deploy.result }}"
          echo "Branch: ${{ github.ref }}"
          echo "Event: ${{ github.event_name }}"
          
          if [[ "${{ needs.test.result }}" == "success" ]]; then
            echo "âœ… Tests: PASSED"
          else
            echo "âŒ Tests: FAILED"
          fi
          
          if [[ "${{ needs.deploy.result }}" == "success" ]]; then
            echo "âœ… Deployment: COMPLETED"
          elif [[ "${{ needs.deploy.result }}" == "skipped" ]]; then
            echo "â­ï¸ Deployment: SKIPPED (not main branch or tests failed)"
          else
            echo "âŒ Deployment: FAILED"
          fi