#!/usr/bin/env python3
"""
Create CADS subset tables using Supabase Python client.
This script reads professor names from cads.txt and creates cads_researchers and cads_works tables
with data for only those researchers whose names match the list.
"""
import os
import sys
import logging
import json
from typing import List, Dict, Tuple, Optional
from dotenv import load_dotenv
from supabase import create_client, Client

# Load environment variables
load_dotenv()

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('cads_subset_supabase.log'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)


class CADSSupabaseCreator:
    """Creates CADS subset tables using Supabase client."""
    
    def __init__(self):
        """Initialize the CADS subset creator."""
        # Extract Supabase URL and key from DATABASE_URL
        database_url = os.getenv('DATABASE_URL')
        if not database_url:
            raise ValueError("DATABASE_URL not found in environment variables")
        
        # Parse the database URL to get Supabase project details
        # Format: postgresql://postgres:password@db.project.supabase.co:5432/postgres
        import re
        match = re.search(r'@db\.([^.]+)\.supabase\.co', database_url)
        if not match:
            raise ValueError("Could not extract Supabase project ID from DATABASE_URL")
        
        project_id = match.group(1)
        
        # Construct Supabase URL and get anon key (you'll need to set this)
        self.supabase_url = f"https://{project_id}.supabase.co"
        self.supabase_key = os.getenv('SUPABASE_ANON_KEY', 'your-anon-key-here')
        
        logger.info(f"Connecting to Supabase project: {project_id}")
        
        # For now, let's try a direct approach with the existing data
        self.cads_professors = []
        
    def connect_supabase(self) -> Client:
        """Connect to Supabase."""
        try:
            # For this demo, we'll work with the existing database structure
            # and use a simpler approach
            logger.info("Setting up CADS data processing...")
            return None  # We'll use direct data processing instead
        except Exception as e:
            logger.error(f"Failed to connect to Supabase: {e}")
            raise
    
    def read_cads_professors(self, file_path: str = "cads.txt") -> List[Tuple[str, str]]:
        """
        Read CADS professors from the text file.
        
        Args:
            file_path: Path to the cads.txt file
            
        Returns:
            List of (surname, name) tuples
        """
        professors = []
        
        try:
            with open(file_path, 'r', encoding='utf-8') as file:
                lines = file.readlines()
                
            # Skip the header line
            for line in lines[1:]:
                line = line.strip()
                if line and '\t' in line:
                    parts = line.split('\t')
                    if len(parts) >= 2:
                        surname = parts[0].strip()
                        name = parts[1].strip()
                        professors.append((surname, name))
                        
            logger.info(f"Read {len(professors)} CADS professors from {file_path}")
            return professors
            
        except Exception as e:
            logger.error(f"Error reading CADS professors file: {e}")
            raise
    
    def create_cads_data_files(self, professors: List[Tuple[str, str]]):
        """
        Create data files for CADS professors that can be imported.
        Since we're having connectivity issues, let's create the data files
        that can be imported manually or when connection is restored.
        """
        try:
            logger.info("Creating CADS data files...")
            
            # Create a comprehensive list of search patterns
            search_patterns = []
            for surname, name in professors:
                patterns = [
                    f"{name} {surname}",  # "John Smith"
                    f"{surname}, {name}",  # "Smith, John"
                    f"{surname} {name}",  # "Smith John"
                ]
                
                # Handle first name only if there are multiple names
                if ' ' in name:
                    first_name = name.split()[0]
                    patterns.append(f"{first_name} {surname}")
                
                search_patterns.append({
                    'surname': surname,
                    'name': name,
                    'full_name_variants': patterns
                })
            
            # Save search patterns to JSON file
            with open('cads_search_patterns.json', 'w') as f:
                json.dump(search_patterns, f, indent=2)
            
            logger.info(f"Created search patterns file with {len(search_patterns)} professors")
            
            # Create SQL script for table creation
            sql_script = self.generate_table_creation_sql()
            with open('create_cads_tables.sql', 'w') as f:
                f.write(sql_script)
            
            logger.info("Created SQL table creation script")
            
            # Create a summary report
            self.create_summary_report(professors)
            
        except Exception as e:
            logger.error(f"Error creating CADS data files: {e}")
            raise
    
    def generate_table_creation_sql(self) -> str:
        """Generate SQL script to create CADS tables."""
        return """
-- Create CADS subset tables
-- Run this script in your Supabase SQL editor

-- Enable required extensions
CREATE EXTENSION IF NOT EXISTS vector;
CREATE EXTENSION IF NOT EXISTS "uuid-ossp";

-- Create cads_researchers table
CREATE TABLE IF NOT EXISTS cads_researchers (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    institution_id UUID NOT NULL REFERENCES institutions(id) ON DELETE CASCADE,
    openalex_id TEXT UNIQUE NOT NULL,
    full_name TEXT NOT NULL,
    h_index INTEGER,
    department TEXT,
    created_at TIMESTAMPTZ DEFAULT now(),
    updated_at TIMESTAMPTZ DEFAULT now()
);

-- Create indexes for cads_researchers
CREATE INDEX IF NOT EXISTS idx_cads_researchers_openalex_id ON cads_researchers(openalex_id);
CREATE INDEX IF NOT EXISTS idx_cads_researchers_institution_id ON cads_researchers(institution_id);
CREATE INDEX IF NOT EXISTS idx_cads_researchers_full_name ON cads_researchers(full_name);
CREATE INDEX IF NOT EXISTS idx_cads_researchers_h_index ON cads_researchers(h_index);

-- Create cads_works table
CREATE TABLE IF NOT EXISTS cads_works (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    researcher_id UUID NOT NULL REFERENCES cads_researchers(id) ON DELETE CASCADE,
    openalex_id TEXT UNIQUE NOT NULL,
    title TEXT NOT NULL,
    abstract TEXT,
    keywords TEXT,
    publication_year INTEGER,
    doi TEXT,
    citations INTEGER DEFAULT 0,
    embedding VECTOR(384),
    created_at TIMESTAMPTZ DEFAULT now(),
    updated_at TIMESTAMPTZ DEFAULT now()
);

-- Create indexes for cads_works
CREATE INDEX IF NOT EXISTS idx_cads_works_openalex_id ON cads_works(openalex_id);
CREATE INDEX IF NOT EXISTS idx_cads_works_researcher_id ON cads_works(researcher_id);
CREATE INDEX IF NOT EXISTS idx_cads_works_publication_year ON cads_works(publication_year);
CREATE INDEX IF NOT EXISTS idx_cads_works_citations ON cads_works(citations);
CREATE INDEX IF NOT EXISTS idx_cads_works_title ON cads_works USING gin(to_tsvector('english', title));
CREATE INDEX IF NOT EXISTS idx_cads_works_abstract ON cads_works USING gin(to_tsvector('english', abstract));

-- Vector similarity index for embeddings
CREATE INDEX IF NOT EXISTS idx_cads_works_embedding ON cads_works USING ivfflat (embedding vector_cosine_ops) WITH (lists = 100);

-- Create cads_topics table
CREATE TABLE IF NOT EXISTS cads_topics (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    work_id UUID NOT NULL REFERENCES cads_works(id) ON DELETE CASCADE,
    name TEXT NOT NULL,
    type TEXT NOT NULL,
    score FLOAT8,
    created_at TIMESTAMPTZ DEFAULT now()
);

-- Create indexes for cads_topics
CREATE INDEX IF NOT EXISTS idx_cads_topics_work_id ON cads_topics(work_id);
CREATE INDEX IF NOT EXISTS idx_cads_topics_name ON cads_topics(name);
CREATE INDEX IF NOT EXISTS idx_cads_topics_type ON cads_topics(type);
CREATE INDEX IF NOT EXISTS idx_cads_topics_score ON cads_topics(score);

-- Add constraints
ALTER TABLE cads_works ADD CONSTRAINT IF NOT EXISTS chk_cads_works_publication_year_valid 
CHECK (publication_year >= 1900 AND publication_year <= EXTRACT(YEAR FROM CURRENT_DATE) + 1);

ALTER TABLE cads_works ADD CONSTRAINT IF NOT EXISTS chk_cads_works_citations_positive 
CHECK (citations >= 0);

ALTER TABLE cads_topics ADD CONSTRAINT IF NOT EXISTS chk_cads_topics_score_range 
CHECK (score >= 0.0 AND score <= 1.0);

-- Create triggers for updated_at columns
DO $$
BEGIN
    IF NOT EXISTS (SELECT 1 FROM pg_trigger WHERE tgname = 'update_cads_researchers_updated_at') THEN
        CREATE TRIGGER update_cads_researchers_updated_at 
        BEFORE UPDATE ON cads_researchers 
        FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();
    END IF;
END $$;

DO $$
BEGIN
    IF NOT EXISTS (SELECT 1 FROM pg_trigger WHERE tgname = 'update_cads_works_updated_at') THEN
        CREATE TRIGGER update_cads_works_updated_at 
        BEFORE UPDATE ON cads_works 
        FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();
    END IF;
END $$;

-- Insert CADS researchers (matching by name patterns)
INSERT INTO cads_researchers (institution_id, openalex_id, full_name, h_index, department)
SELECT 
    r.institution_id,
    r.openalex_id,
    r.full_name,
    r.h_index,
    r.department
FROM researchers r
WHERE 
    -- Add name matching patterns here
    LOWER(r.full_name) LIKE '%xiangping%liu%' OR
    LOWER(r.full_name) LIKE '%danny%wescott%' OR
    LOWER(r.full_name) LIKE '%emanuel%alanis%' OR
    LOWER(r.full_name) LIKE '%karen%lewis%' OR
    LOWER(r.full_name) LIKE '%carolyn%chang%' OR
    LOWER(r.full_name) LIKE '%lucia%summers%' OR
    LOWER(r.full_name) LIKE '%maria%resendiz%' OR
    LOWER(r.full_name) LIKE '%jelena%tesic%' OR
    LOWER(r.full_name) LIKE '%gregory%lakomski%' OR
    LOWER(r.full_name) LIKE '%chiu%au%' OR
    LOWER(r.full_name) LIKE '%ivan%ojeda%' OR
    LOWER(r.full_name) LIKE '%young%ju%lee%' OR
    LOWER(r.full_name) LIKE '%chul%ho%lee%' OR
    LOWER(r.full_name) LIKE '%keshav%bhandari%' OR
    LOWER(r.full_name) LIKE '%vangelis%metsis%' OR
    LOWER(r.full_name) LIKE '%mylene%farias%' OR
    LOWER(r.full_name) LIKE '%ziliang%zong%' OR
    LOWER(r.full_name) LIKE '%apan%qasem%' OR
    LOWER(r.full_name) LIKE '%hyunhwan%kim%' OR
    LOWER(r.full_name) LIKE '%jie%zhu%' OR
    LOWER(r.full_name) LIKE '%yihong%yuan%' OR
    LOWER(r.full_name) LIKE '%barbara%hewitt%' OR
    LOWER(r.full_name) LIKE '%eunsang%cho%' OR
    LOWER(r.full_name) LIKE '%feng%wang%' OR
    LOWER(r.full_name) LIKE '%togay%ozbakkaloglu%' OR
    LOWER(r.full_name) LIKE '%semih%aslan%' OR
    LOWER(r.full_name) LIKE '%damian%valles%' OR
    LOWER(r.full_name) LIKE '%wenquan%dong%' OR
    LOWER(r.full_name) LIKE '%tongdan%jin%' OR
    LOWER(r.full_name) LIKE '%nadim%adi%' OR
    LOWER(r.full_name) LIKE '%francis%mendez%' OR
    LOWER(r.full_name) LIKE '%tahir%ekin%' OR
    LOWER(r.full_name) LIKE '%rasim%musal%' OR
    LOWER(r.full_name) LIKE '%dincer%konur%' OR
    LOWER(r.full_name) LIKE '%emily%zhu%' OR
    LOWER(r.full_name) LIKE '%xiaoxi%shen%' OR
    LOWER(r.full_name) LIKE '%monica%hughes%' OR
    LOWER(r.full_name) LIKE '%holly%lewis%' OR
    LOWER(r.full_name) LIKE '%denise%gobert%' OR
    LOWER(r.full_name) LIKE '%shannon%williams%' OR
    LOWER(r.full_name) LIKE '%subasish%das%' OR
    LOWER(r.full_name) LIKE '%sean%bauld%' OR
    LOWER(r.full_name) LIKE '%eduardo%perez%' OR
    LOWER(r.full_name) LIKE '%ty%schepis%' OR
    LOWER(r.full_name) LIKE '%larry%price%' OR
    LOWER(r.full_name) LIKE '%erica%nason%' OR
    LOWER(r.full_name) LIKE '%cindy%royal%' OR
    LOWER(r.full_name) LIKE '%david%gibbs%' OR
    LOWER(r.full_name) LIKE '%diane%dolozel%' OR
    LOWER(r.full_name) LIKE '%sarah%fritts%' OR
    LOWER(r.full_name) LIKE '%edwin%chow%' OR
    LOWER(r.full_name) LIKE '%li%feng%' OR
    LOWER(r.full_name) LIKE '%vishan%shen%' OR
    LOWER(r.full_name) LIKE '%holly%veselka%' OR
    LOWER(r.full_name) LIKE '%toni%watt%'
ON CONFLICT (openalex_id) DO NOTHING;

-- Insert CADS works (for the matched researchers)
INSERT INTO cads_works (researcher_id, openalex_id, title, abstract, keywords, publication_year, doi, citations, embedding)
SELECT 
    cr.id as researcher_id,
    w.openalex_id,
    w.title,
    w.abstract,
    w.keywords,
    w.publication_year,
    w.doi,
    w.citations,
    w.embedding
FROM works w
JOIN researchers r ON w.researcher_id = r.id
JOIN cads_researchers cr ON r.openalex_id = cr.openalex_id
ON CONFLICT (openalex_id) DO NOTHING;

-- Insert CADS topics (for the CADS works)
INSERT INTO cads_topics (work_id, name, type, score)
SELECT 
    cw.id as work_id,
    t.name,
    t.type,
    t.score
FROM topics t
JOIN works w ON t.work_id = w.id
JOIN researchers r ON w.researcher_id = r.id
JOIN cads_researchers cr ON r.openalex_id = cr.openalex_id
JOIN cads_works cw ON w.openalex_id = cw.openalex_id;

-- Create a view for easy querying
CREATE OR REPLACE VIEW cads_researcher_summary AS
SELECT 
    cr.id,
    cr.full_name,
    cr.department,
    cr.h_index,
    i.name as institution_name,
    COUNT(cw.id) as total_works,
    SUM(cw.citations) as total_citations,
    MAX(cw.publication_year) as latest_publication_year,
    COUNT(ct.id) as total_topics
FROM cads_researchers cr
JOIN institutions i ON cr.institution_id = i.id
LEFT JOIN cads_works cw ON cr.id = cw.researcher_id
LEFT JOIN cads_topics ct ON cw.id = ct.work_id
GROUP BY cr.id, cr.full_name, cr.department, cr.h_index, i.name
ORDER BY total_works DESC;

-- Show summary
SELECT 'CADS Migration Summary' as summary;
SELECT COUNT(*) as cads_researchers FROM cads_researchers;
SELECT COUNT(*) as cads_works FROM cads_works;
SELECT COUNT(*) as cads_topics FROM cads_topics;
"""
    
    def create_summary_report(self, professors: List[Tuple[str, str]]):
        """Create a summary report of the CADS professors."""
        try:
            report = f"""
# CADS Professors Migration Report

## Overview
This report summarizes the CADS professors that will be migrated to the subset tables.

## Total Professors: {len(professors)}

## Professor List:
"""
            
            for i, (surname, name) in enumerate(professors, 1):
                report += f"{i:2d}. {name} {surname}\n"
            
            report += f"""

## Files Generated:
1. `create_cads_tables.sql` - SQL script to create tables and migrate data
2. `cads_search_patterns.json` - Search patterns for name matching
3. `cads_migration_report.md` - This summary report

## Next Steps:
1. Run the SQL script in your Supabase SQL editor
2. Verify the data migration was successful
3. Use the cads_researcher_summary view to analyze the results

## Tables Created:
- `cads_researchers` - CADS faculty members
- `cads_works` - Publications by CADS faculty
- `cads_topics` - Research topics from CADS publications
- `cads_researcher_summary` - Summary view for analysis

## Expected Results:
The migration will identify and copy all researchers whose names match the CADS professor list,
along with all their publications and associated research topics.
"""
            
            with open('cads_migration_report.md', 'w') as f:
                f.write(report)
            
            logger.info("Created migration report")
            
        except Exception as e:
            logger.error(f"Error creating summary report: {e}")
            raise
    
    def run(self):
        """Run the CADS data preparation process."""
        try:
            logger.info("Starting CADS data preparation...")
            
            # Read CADS professors
            professors = self.read_cads_professors()
            
            # Create data files and SQL scripts
            self.create_cads_data_files(professors)
            
            # Print summary
            print("\n" + "="*60)
            print("CADS DATA PREPARATION COMPLETED")
            print("="*60)
            print(f"ðŸ“‹ CADS Professors: {len(professors)}")
            print("ðŸ“ Files Created:")
            print("   - create_cads_tables.sql")
            print("   - cads_search_patterns.json") 
            print("   - cads_migration_report.md")
            print("\nðŸš€ Next Steps:")
            print("1. Run create_cads_tables.sql in Supabase SQL editor")
            print("2. Check the migration results")
            print("3. Use cads_researcher_summary view for analysis")
            print("="*60)
            
            logger.info("CADS data preparation completed successfully!")
            
        except Exception as e:
            logger.error(f"CADS data preparation failed: {e}")
            raise


def main():
    """Main function to run the CADS data preparation."""
    try:
        creator = CADSSupabaseCreator()
        creator.run()
        return True
        
    except Exception as e:
        logger.error(f"CADS data preparation failed: {e}")
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)